{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashubG/first-contributions/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PU_KwWyh1r_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import the datasets"
      ],
      "metadata": {
        "id": "gaNC5J7TiS3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/test.csv')\n",
        "train = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "uPwPLOHWiVl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "vk7tbFaVjWdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop((train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index),\n",
        "           inplace=True)  # Remove obvious outliers\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "y = np.log1p(train['HotelValue'])    # Log-transform target for symmetry\n",
        "train_ids = train['Id']\n",
        "test_ids  = test['Id']\n",
        "\n",
        "# Drop ID and target from features\n",
        "train.drop(['Id','HotelValue'], axis=1, inplace=True)\n",
        "test.drop('Id', axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Combine for Preprocessing\n",
        "# ---------------------------\n",
        "all_data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Drop Sparse/Irrelevant Features\n",
        "# ---------------------------\n",
        "# Remove columns with mostly missing or poor information\n",
        "drop_cols = [\n",
        "    'ServiceLaneType','FacadeType','PoolQuality','BoundaryFence','ExtraFacility',\n",
        "    'PlotConfiguration','NearbyTransport1','NearbyTransport2','UtilityAccess'\n",
        "]\n",
        "all_data.drop(columns=[c for c in drop_cols if c in all_data.columns], inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Feature Engineering\n",
        "# ---------------------------\n",
        "# Convert some numeric categories to strings (for one-hot later)\n",
        "all_data['PropertyClass'] = all_data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area and Room features\n",
        "all_data['TotalSF'] = (\n",
        "    all_data['BasementTotalSF'] +\n",
        "    all_data['GroundFloorArea'] +\n",
        "    all_data['UpperFloorArea']\n",
        ")\n",
        "all_data['TotalBath'] = (\n",
        "    all_data['FullBaths'] +\n",
        "    0.5 * all_data['HalfBaths'] +\n",
        "    all_data['BasementFullBaths'] +\n",
        "    0.5 * all_data['BasementHalfBaths']\n",
        ")\n",
        "all_data['TotalPorchSF'] = (\n",
        "    all_data['OpenVerandaArea'] +\n",
        "    all_data['EnclosedVerandaArea'] +\n",
        "    all_data['SeasonalPorchArea'] +\n",
        "    all_data['ScreenPorchArea']\n",
        ")\n",
        "# Age and renovation features\n",
        "all_data['HotelAge'] = all_data['YearSold'] - all_data['ConstructionYear']\n",
        "all_data['RemodAge'] = all_data['YearSold'] - all_data['RenovationYear']\n",
        "all_data['WasRemodeled'] = (all_data['RemodAge'] > 0).astype(int)\n",
        "all_data['IsNew'] = (all_data['YearSold'] == all_data['ConstructionYear']).astype(int)\n",
        "# Flags for amenities\n",
        "all_data['HasPool'] = (all_data['SwimmingPoolArea'] > 0).astype(int)\n",
        "all_data['HasGarage'] = (all_data['ParkingArea'] > 0).astype(int)\n",
        "all_data['HasBasement'] = (all_data['BasementTotalSF'] > 0).astype(int)\n",
        "all_data['HasLounge'] = (all_data['Lounges'] > 0).astype(int)\n",
        "# Polynomial / interaction features\n",
        "all_data['OverallQuality_sq'] = all_data['OverallQuality']**2\n",
        "all_data['OverallQuality_cub'] = all_data['OverallQuality']**3\n",
        "all_data['OverallQuality_x_TotalSF']  = all_data['OverallQuality'] * all_data['TotalSF']\n",
        "all_data['OverallQuality_x_HotelAge'] = all_data['OverallQuality'] * all_data['HotelAge']\n",
        "# New ratio features\n",
        "all_data['BuiltPct']      = all_data['TotalSF'] / (all_data['LandArea'] + 1)\n",
        "all_data['Area_per_Room'] = all_data['UsableArea'] / (all_data['TotalRooms'] + 1)\n",
        "all_data['Baths_to_Rooms'] = all_data['TotalBath'] / (all_data['TotalRooms'] + 1)\n",
        "all_data['BasementRatio']  = all_data['BasementTotalSF'] / (all_data['TotalSF'] + 1)\n",
        "\n",
        "# ---------------------------\n",
        "# Drop Redundant Originals (after creating features)\n",
        "# ---------------------------\n",
        "drop_orig = [\n",
        "    'OpenVerandaArea','EnclosedVerandaArea','SeasonalPorchArea','ScreenPorchArea',\n",
        "    'LowQualityArea','FacadeArea','BasementFacilitySF2'\n",
        "]\n",
        "for col in drop_orig:\n",
        "    if col in all_data.columns:\n",
        "        all_data.drop(col, axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Imputation for Remaining Missing Data\n",
        "# ---------------------------\n",
        "# Many missing in RoadAccessLength; fill by District median\n",
        "if 'RoadAccessLength' in all_data.columns:\n",
        "    all_data['RoadAccessLength'] = all_data.groupby('District')['RoadAccessLength']\\\n",
        "                                          .transform(lambda x: x.fillna(x.median()))\n",
        "    # --- FIX 1 (No inplace=True) ---\n",
        "    all_data['RoadAccessLength'] = all_data['RoadAccessLength'].fillna(all_data['RoadAccessLength'].median())\n",
        "\n",
        "# Fill small gaps with zeros or modes\n",
        "if 'FacadeArea' in all_data.columns:\n",
        "    all_data['FacadeArea'].fillna(0, inplace=True) # This one is fine, not a chained assignment\n",
        "\n",
        "if 'ElectricalSystem' in all_data.columns:\n",
        "    # --- FIX 2 (No inplace=True) ---\n",
        "    all_data['ElectricalSystem'] = all_data['ElectricalSystem'].fillna(all_data['ElectricalSystem'].mode()[0])\n",
        "\n",
        "# Any remaining numeric NaNs\n",
        "num_cols = all_data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = all_data.select_dtypes(exclude=[np.number]).columns\n",
        "all_data[num_cols] = all_data[num_cols].fillna(0)\n",
        "all_data[cat_cols] = all_data[cat_cols].fillna('None')\n",
        "\n",
        "# ---------------------------\n",
        "# Ordinal Encoding for Quality Features\n",
        "# ---------------------------\n",
        "qual_map = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'None':0}\n",
        "for col in ['ExteriorQuality','ExteriorCondition','HeatingQuality','KitchenQuality']:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = all_data[col].map(qual_map).astype(int)\n",
        "# Categorical mappings\n",
        "if 'LandSlope' in all_data.columns:\n",
        "    all_data['LandSlope'] = all_data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3).astype(int)\n",
        "if 'PlotShape' in all_data.columns:\n",
        "    all_data['PlotShape'] = all_data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4).astype(int)\n",
        "# Binary encoding\n",
        "all_data['CentralAC'] = all_data['CentralAC'].map({'Y':1,'N':0}).astype(int)\n",
        "\n",
        "# ---------------------------\n",
        "# Log-transform Highly Skewed Numerics\n",
        "# ---------------------------\n",
        "for col in ['ExtraFacilityValue','LandArea','BasementHalfBaths']:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = np.log1p(all_data[col])\n",
        "\n",
        "# Drop SwimmingPoolArea due to extreme skew & rarity (we have HasPool flag)\n",
        "if 'SwimmingPoolArea' in all_data.columns:\n",
        "    all_data.drop('SwimmingPoolArea', axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# One-Hot Encoding\n",
        "# ---------------------------\n",
        "all_data = pd.get_dummies(all_data, drop_first=True)\n",
        "print(\"Final feature matrix shape:\", all_data.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# Train/Test Split for Modeling\n",
        "# ---------------------------\n",
        "X = all_data.iloc[:train.shape[0], :].values\n",
        "X_test_final = all_data.iloc[train.shape[0]:, :].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvmFi5_DjeP4",
        "outputId": "b5619199-44fa-4e23-938a-e5a9d63a3a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature matrix shape: (1458, 233)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agam Roy"
      ],
      "metadata": {
        "id": "hNrEIh1O0bxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes Classifier\n"
      ],
      "metadata": {
        "id": "DSR_cofcRbE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bayes_classifier_hotel_value.py\n",
        "# Train a Gaussian Naive Bayes classifier (Bayes) with same preprocessing and GridSearchCV.\n",
        "# Predictions are mapped back to median HotelValue per class so submission retains numeric HotelValue.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "\n",
        "# ====================\n",
        "# CONFIG\n",
        "# ====================\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "TRAIN_PATH = '/content/train.csv'\n",
        "TEST_PATH  = '/content/test.csv'\n",
        "SUB_PATH   = '/content/sample_submission.csv'\n",
        "OUTPUT_PATH = 'submission.csv'\n",
        "\n",
        "# ====================\n",
        "# LOAD\n",
        "# ====================\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SUB_PATH)\n",
        "\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# ====================\n",
        "# Create classification target (terciles) + mapping to numeric medians\n",
        "# ====================\n",
        "# We'll bin original HotelValue into 3 classes (low/mid/high) using quantiles.\n",
        "# Keep the original HotelValue for mapping medians later.\n",
        "train_orig = train.copy()\n",
        "# If there are ties that make qcut fail, use rank-based binning as fallback.\n",
        "try:\n",
        "    train['ValueClass'] = pd.qcut(train['HotelValue'], q=3, labels=['low','mid','high'])\n",
        "except Exception:\n",
        "    # fallback to rank-based bins\n",
        "    train['ValueClass'] = pd.qcut(train['HotelValue'].rank(method='first'), q=3, labels=['low','mid','high'])\n",
        "\n",
        "# Map class string labels to integers for classifier\n",
        "class_order = ['low', 'mid', 'high']\n",
        "train['ValueClassLabel'] = train['ValueClass'].map({lab:i for i,lab in enumerate(class_order)})\n",
        "\n",
        "# Compute representative numeric HotelValue for each class (median)\n",
        "class_medians = train_orig.groupby(pd.qcut(train_orig['HotelValue'], q=3, labels=class_order))['HotelValue'].median().to_dict()\n",
        "# If qcut fallback used, ensure medians align\n",
        "if set(class_medians.keys()) != set(class_order):\n",
        "    # recompute using labels from train['ValueClass']\n",
        "    class_medians = train_orig.assign(ValueClass=train['ValueClass']).groupby('ValueClass')['HotelValue'].median().to_dict()\n",
        "\n",
        "print(\"Class medians (mapping class -> numeric HotelValue):\", class_medians)\n",
        "\n",
        "y_class = train['ValueClassLabel'].values\n",
        "test_ids = test['Id'].copy()\n",
        "\n",
        "# Drop target/id columns from train/test before combining\n",
        "train_drop = train.drop(['HotelValue','ValueClass','ValueClassLabel'], axis=1, errors='ignore')\n",
        "test_drop  = test.drop(['Id'], axis=1, errors='ignore')\n",
        "\n",
        "# ====================\n",
        "# COMBINE FOR PREPROCESSING\n",
        "# ====================\n",
        "data = pd.concat([train_drop, test_drop], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ====================\n",
        "# FEATURE ENGINEERING (preserve your transforms)\n",
        "# ====================\n",
        "print(\"Performing feature engineering...\")\n",
        "if 'PropertyClass' in data.columns:\n",
        "    data['PropertyClass'] = data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area-based features\n",
        "for col in ['BasementTotalSF', 'GroundFloorArea', 'UpperFloorArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalSF'] = data['BasementTotalSF'].fillna(0) + data['GroundFloorArea'].fillna(0) + data['UpperFloorArea'].fillna(0)\n",
        "\n",
        "# Bath features\n",
        "for col in ['FullBaths', 'HalfBaths', 'BasementFullBaths', 'BasementHalfBaths']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalBath'] = data['FullBaths'].fillna(0) + 0.5*data['HalfBaths'].fillna(0) + data['BasementFullBaths'].fillna(0) + 0.5*data['BasementHalfBaths'].fillna(0)\n",
        "\n",
        "# Porch\n",
        "for col in ['OpenVerandaArea', 'EnclosedVerandaArea', 'SeasonalPorchArea', 'ScreenPorchArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalPorchSF'] = data['OpenVerandaArea'].fillna(0) + data['EnclosedVerandaArea'].fillna(0) + data['SeasonalPorchArea'].fillna(0) + data['ScreenPorchArea'].fillna(0)\n",
        "\n",
        "# Age features\n",
        "for col in ['YearSold','ConstructionYear','RenovationYear']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = data.get('YearSold', 0)\n",
        "data['HotelAge'] = data['YearSold'].fillna(0) - data['ConstructionYear'].fillna(data['YearSold'].fillna(0))\n",
        "data['RemodAge'] = data['YearSold'].fillna(0) - data['RenovationYear'].fillna(data['YearSold'].fillna(0))\n",
        "\n",
        "# Binary flags\n",
        "data['WasRemodeled'] = (data.get('RenovationYear', data['ConstructionYear']) != data.get('ConstructionYear', data['RenovationYear'])).astype(int)\n",
        "data['IsNew'] = (data['ConstructionYear'] == data['YearSold']).astype(int) if ('ConstructionYear' in data.columns and 'YearSold' in data.columns) else 0\n",
        "data['HasPool'] = (data['SwimmingPoolArea'] > 0).astype(int) if 'SwimmingPoolArea' in data.columns else 0\n",
        "data['HasGarage'] = (data['ParkingArea'] > 0).astype(int) if 'ParkingArea' in data.columns else 0\n",
        "data['HasBasement'] = (data['BasementTotalSF'] > 0).astype(int) if 'BasementTotalSF' in data.columns else 0\n",
        "data['HasLounge'] = (data['Lounges'] > 0).astype(int) if 'Lounges' in data.columns else 0\n",
        "\n",
        "# Polynomial & interactions\n",
        "if 'OverallQuality' not in data.columns:\n",
        "    data['OverallQuality'] = 0\n",
        "data['OverallQuality_sq'] = data['OverallQuality']**2\n",
        "data['OverallQuality_cub'] = data['OverallQuality']**3\n",
        "data['OverallQuality_x_TotalSF'] = data['OverallQuality'] * data['TotalSF']\n",
        "data['OverallQuality_x_HotelAge'] = data['OverallQuality'] * data['HotelAge']\n",
        "\n",
        "# Drop columns you previously considered weak\n",
        "drop_cols = [\n",
        "    'ServiceLaneType', 'FacadeType', 'BoundaryFence', 'ExtraFacility',\n",
        "    'UtilityAccess', 'NearbyTransport1', 'NearbyTransport2'\n",
        "]\n",
        "data.drop(columns=[c for c in drop_cols if c in data.columns], inplace=True)\n",
        "\n",
        "# ====================\n",
        "# MISSING VALUES (kept your logic)\n",
        "# ====================\n",
        "print(\"Handling missing values...\")\n",
        "none_cols = [\n",
        "    'PoolQuality', 'BasementHeight', 'BasementCondition', 'BasementExposure',\n",
        "    'BasementFacilityType1', 'BasementFacilityType2', 'ParkingType',\n",
        "    'ParkingFinish', 'ParkingQuality', 'ParkingCondition', 'LoungeQuality'\n",
        "]\n",
        "for col in none_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna('None')\n",
        "\n",
        "mode_cols = ['KitchenQuality', 'PropertyFunctionality', 'ZoningCategory']\n",
        "for col in mode_cols:\n",
        "    if col in data.columns:\n",
        "        if data[col].isnull().any():\n",
        "            data[col] = data[col].fillna(data[col].mode().iloc[0])\n",
        "\n",
        "zero_cols = [\n",
        "    'BasementFacilitySF1', 'BasementFacilitySF2', 'BasementUnfinishedSF',\n",
        "    'BasementTotalSF', 'BasementFullBaths', 'BasementHalfBaths',\n",
        "    'FacadeArea', 'ParkingArea', 'ParkingCapacity'\n",
        "]\n",
        "for col in zero_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna(0)\n",
        "\n",
        "if 'RoadAccessLength' in data.columns and 'District' in data.columns:\n",
        "    data['RoadAccessLength'] = data.groupby('District')['RoadAccessLength'].transform(lambda x: x.fillna(x.median()))\n",
        "    data['RoadAccessLength'].fillna(data['RoadAccessLength'].median(), inplace=True)\n",
        "\n",
        "# catch-all\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(exclude=[np.number]).columns\n",
        "data[num_cols] = data[num_cols].fillna(0)\n",
        "data[cat_cols] = data[cat_cols].fillna('None')\n",
        "\n",
        "# ====================\n",
        "# ENCODING & SKEW TRANSFORMS\n",
        "# ====================\n",
        "print(\"Encoding categorical features and transforming skewness...\")\n",
        "qual_map = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0}\n",
        "for col in ['ExteriorQuality', 'ExteriorCondition', 'HeatingQuality', 'KitchenQuality',\n",
        "            'LoungeQuality', 'BasementHeight', 'BasementCondition']:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].map(qual_map).fillna(0)\n",
        "\n",
        "if 'CentralAC' in data.columns:\n",
        "    data['CentralAC'] = data['CentralAC'].map({'Y':1, 'N':0}).fillna(0).astype(int)\n",
        "if 'LandSlope' in data.columns:\n",
        "    data['LandSlope'] = data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3)\n",
        "if 'PlotShape' in data.columns:\n",
        "    data['PlotShape'] = data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4)\n",
        "\n",
        "numeric_feats = data.select_dtypes(include=[np.number]).columns\n",
        "skewed = data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "skewed_feats = skewed[skewed.abs() > 0.7].index.tolist()\n",
        "for col in skewed_feats:\n",
        "    if data[col].nunique() > 2:\n",
        "        data[col] = np.log1p(data[col].clip(lower=0))\n",
        "\n",
        "# One-hot encode\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# ====================\n",
        "# SPLIT BACK\n",
        "# ====================\n",
        "X = data.iloc[:len(train_drop), :].copy()\n",
        "X_test = data.iloc[len(train_drop):, :].copy()\n",
        "\n",
        "# Align to be safe\n",
        "X, X_test = X.align(X_test, join='inner', axis=1)\n",
        "print(f\"Final X shape: {X.shape}, X_test shape: {X_test.shape}\")\n",
        "\n",
        "# ====================\n",
        "# PIPELINE + GRIDSEARCH (GaussianNB)\n",
        "# ====================\n",
        "print(\"Setting up GaussianNB pipeline and GridSearchCV...\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('var_thresh', VarianceThreshold(threshold=1e-5)),\n",
        "    ('scale', StandardScaler()),\n",
        "    ('clf', GaussianNB())\n",
        "])\n",
        "\n",
        "# grid for GaussianNB: var_smoothing is the main hyperparameter\n",
        "param_grid = {\n",
        "    'clf__var_smoothing': np.logspace(-12, -6, 7)\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_macro',       # balanced across classes\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "print(\"Running GridSearchCV (this tunes var_smoothing for GaussianNB)...\")\n",
        "grid.fit(X, y_class)\n",
        "\n",
        "best_score = grid.best_score_\n",
        "best_params = grid.best_params_\n",
        "print(\"Best CV f1_macro:\", best_score)\n",
        "print(\"Best params:\", best_params)\n",
        "\n",
        "# ====================\n",
        "# Predict on test, map class -> numeric median HotelValue\n",
        "# ====================\n",
        "best_model = grid.best_estimator_\n",
        "pred_class_labels = best_model.predict(X_test)  # integers 0,1,2 corresponding to low/mid/high\n",
        "\n",
        "# Map back to class names and then to median HotelValue\n",
        "inv_map = {i:lab for i,lab in enumerate(class_order)}\n",
        "pred_class_names = [inv_map[int(c)] for c in pred_class_labels]\n",
        "pred_numeric = [class_medians[name] for name in pred_class_names]\n",
        "\n",
        "# Save submission (Id + HotelValue numeric mapped from class medians)\n",
        "submission = pd.DataFrame({'Id': test_ids, 'HotelValue': pred_numeric})\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"✅ Submission saved to {OUTPUT_PATH}\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4VYCj5dOtCi",
        "outputId": "e18e3903-5275-4640-f93a-c6438eb423f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1200, 81), Test shape: (260, 80)\n",
            "Class medians (mapping class -> numeric HotelValue): {'low': 119500.0, 'mid': 165075.0, 'high': 240000.0}\n",
            "Performing feature engineering...\n",
            "Handling missing values...\n",
            "Encoding categorical features and transforming skewness...\n",
            "Final X shape: (1200, 237), X_test shape: (260, 237)\n",
            "Setting up GaussianNB pipeline and GridSearchCV...\n",
            "Running GridSearchCV (this tunes var_smoothing for GaussianNB)...\n",
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "Best CV f1_macro: 0.6098809844877229\n",
            "Best params: {'clf__var_smoothing': np.float64(1e-06)}\n",
            "✅ Submission saved to submission.csv\n",
            "     Id  HotelValue\n",
            "0   893    165075.0\n",
            "1  1106    240000.0\n",
            "2   414    119500.0\n",
            "3   523    119500.0\n",
            "4  1037    240000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Version\n"
      ],
      "metadata": {
        "id": "ZIUQ5pKDTiYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "# ---------------------------\n",
        "# Settings Using Best code to get best accuracy possible\n",
        "# ---------------------------\n",
        "SEED = 42\n",
        "N_FOLDS = 5  # 5-fold to save time while still robust\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ---------------------------\n",
        "# Load Data\n",
        "# ---------------------------\n",
        "# Load the CSV files into DataFrames\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "train.drop((train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index),\n",
        "           inplace=True)  # Remove obvious outliers\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "y = np.log1p(train['HotelValue'])    # Log-transform target for symmetry\n",
        "train_ids = train['Id']\n",
        "test_ids  = test['Id']\n",
        "\n",
        "# Drop ID and target from features\n",
        "train.drop(['Id','HotelValue'], axis=1, inplace=True)\n",
        "test.drop('Id', axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Combine for Preprocessing\n",
        "# ---------------------------\n",
        "all_data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Drop Sparse/Irrelevant Features\n",
        "# ---------------------------\n",
        "# Remove columns with mostly missing or poor information\n",
        "drop_cols = [\n",
        "    'ServiceLaneType','FacadeType','PoolQuality','BoundaryFence','ExtraFacility',\n",
        "    'PlotConfiguration','NearbyTransport1','NearbyTransport2','UtilityAccess'\n",
        "]\n",
        "all_data.drop(columns=[c for c in drop_cols if c in all_data.columns], inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Feature Engineering\n",
        "# ---------------------------\n",
        "# Convert some numeric categories to strings (for one-hot later)\n",
        "all_data['PropertyClass'] = all_data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area and Room features\n",
        "all_data['TotalSF'] = (\n",
        "    all_data['BasementTotalSF'] +\n",
        "    all_data['GroundFloorArea'] +\n",
        "    all_data['UpperFloorArea']\n",
        ")\n",
        "all_data['TotalBath'] = (\n",
        "    all_data['FullBaths'] +\n",
        "    0.5 * all_data['HalfBaths'] +\n",
        "    all_data['BasementFullBaths'] +\n",
        "    0.5 * all_data['BasementHalfBaths']\n",
        ")\n",
        "all_data['TotalPorchSF'] = (\n",
        "    all_data['OpenVerandaArea'] +\n",
        "    all_data['EnclosedVerandaArea'] +\n",
        "    all_data['SeasonalPorchArea'] +\n",
        "    all_data['ScreenPorchArea']\n",
        ")\n",
        "# Age and renovation features\n",
        "all_data['HotelAge'] = all_data['YearSold'] - all_data['ConstructionYear']\n",
        "all_data['RemodAge'] = all_data['YearSold'] - all_data['RenovationYear']\n",
        "all_data['WasRemodeled'] = (all_data['RemodAge'] > 0).astype(int)\n",
        "all_data['IsNew'] = (all_data['YearSold'] == all_data['ConstructionYear']).astype(int)\n",
        "# Flags for amenities\n",
        "all_data['HasPool'] = (all_data['SwimmingPoolArea'] > 0).astype(int)\n",
        "all_data['HasGarage'] = (all_data['ParkingArea'] > 0).astype(int)\n",
        "all_data['HasBasement'] = (all_data['BasementTotalSF'] > 0).astype(int)\n",
        "all_data['HasLounge'] = (all_data['Lounges'] > 0).astype(int)\n",
        "# Polynomial / interaction features\n",
        "all_data['OverallQuality_sq'] = all_data['OverallQuality']**2\n",
        "all_data['OverallQuality_cub'] = all_data['OverallQuality']**3\n",
        "all_data['OverallQuality_x_TotalSF']  = all_data['OverallQuality'] * all_data['TotalSF']\n",
        "all_data['OverallQuality_x_HotelAge'] = all_data['OverallQuality'] * all_data['HotelAge']\n",
        "# New ratio features\n",
        "all_data['BuiltPct']      = all_data['TotalSF'] / (all_data['LandArea'] + 1)\n",
        "all_data['Area_per_Room'] = all_data['UsableArea'] / (all_data['TotalRooms'] + 1)\n",
        "all_data['Baths_to_Rooms'] = all_data['TotalBath'] / (all_data['TotalRooms'] + 1)\n",
        "all_data['BasementRatio']  = all_data['BasementTotalSF'] / (all_data['TotalSF'] + 1)\n",
        "\n",
        "# ---------------------------\n",
        "# Drop Redundant Originals (after creating features)\n",
        "# ---------------------------\n",
        "drop_orig = [\n",
        "    'OpenVerandaArea','EnclosedVerandaArea','SeasonalPorchArea','ScreenPorchArea',\n",
        "    'LowQualityArea','FacadeArea','BasementFacilitySF2'\n",
        "]\n",
        "for col in drop_orig:\n",
        "    if col in all_data.columns:\n",
        "        all_data.drop(col, axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Imputation for Remaining Missing Data\n",
        "# ---------------------------\n",
        "# Many missing in RoadAccessLength; fill by District median\n",
        "if 'RoadAccessLength' in all_data.columns:\n",
        "    all_data['RoadAccessLength'] = all_data.groupby('District')['RoadAccessLength']\\\n",
        "                                          .transform(lambda x: x.fillna(x.median()))\n",
        "    # --- FIX 1 (No inplace=True) ---\n",
        "    all_data['RoadAccessLength'] = all_data['RoadAccessLength'].fillna(all_data['RoadAccessLength'].median())\n",
        "\n",
        "# Fill small gaps with zeros or modes\n",
        "if 'FacadeArea' in all_data.columns:\n",
        "    all_data['FacadeArea'].fillna(0, inplace=True) # This one is fine, not a chained assignment\n",
        "\n",
        "if 'ElectricalSystem' in all_data.columns:\n",
        "    # --- FIX 2 (No inplace=True) ---\n",
        "    all_data['ElectricalSystem'] = all_data['ElectricalSystem'].fillna(all_data['ElectricalSystem'].mode()[0])\n",
        "\n",
        "# Any remaining numeric NaNs\n",
        "num_cols = all_data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = all_data.select_dtypes(exclude=[np.number]).columns\n",
        "all_data[num_cols] = all_data[num_cols].fillna(0)\n",
        "all_data[cat_cols] = all_data[cat_cols].fillna('None')\n",
        "\n",
        "# ---------------------------\n",
        "# Ordinal Encoding for Quality Features\n",
        "# ---------------------------\n",
        "qual_map = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'None':0}\n",
        "for col in ['ExteriorQuality','ExteriorCondition','HeatingQuality','KitchenQuality']:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = all_data[col].map(qual_map).astype(int)\n",
        "# Categorical mappings\n",
        "if 'LandSlope' in all_data.columns:\n",
        "    all_data['LandSlope'] = all_data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3).astype(int)\n",
        "if 'PlotShape' in all_data.columns:\n",
        "    all_data['PlotShape'] = all_data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4).astype(int)\n",
        "# Binary encoding\n",
        "all_data['CentralAC'] = all_data['CentralAC'].map({'Y':1,'N':0}).astype(int)\n",
        "\n",
        "# ---------------------------\n",
        "# Log-transform Highly Skewed Numerics\n",
        "# ---------------------------\n",
        "for col in ['ExtraFacilityValue','LandArea','BasementHalfBaths']:\n",
        "    if col in all_data.columns:\n",
        "        all_data[col] = np.log1p(all_data[col])\n",
        "\n",
        "# Drop SwimmingPoolArea due to extreme skew & rarity (we have HasPool flag)\n",
        "if 'SwimmingPoolArea' in all_data.columns:\n",
        "    all_data.drop('SwimmingPoolArea', axis=1, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# One-Hot Encoding\n",
        "# ---------------------------\n",
        "all_data = pd.get_dummies(all_data, drop_first=True)\n",
        "print(\"Final feature matrix shape:\", all_data.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# Train/Test Split for Modeling\n",
        "# ---------------------------\n",
        "X = all_data.iloc[:train.shape[0], :].values\n",
        "X_test_final = all_data.iloc[train.shape[0]:, :].values\n",
        "\n",
        "# ---------------------------\n",
        "# Define Models & Ensemble\n",
        "# ---------------------------\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "# LightGBM\n",
        "lgbm = lgb.LGBMRegressor(\n",
        "    objective='regression_l1',\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.01,\n",
        "    num_leaves=31,\n",
        "    max_depth=6,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=0.1,\n",
        "    colsample_bytree=0.5,\n",
        "    subsample=0.7,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    verbosity=-1  # --- FIX 3: Suppress LightGBM warnings ---\n",
        ")\n",
        "# XGBoost\n",
        "xgbr = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=5,\n",
        "    subsample=0.7,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_alpha=0.005,\n",
        "    reg_lambda=0.9,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1\n",
        ")\n",
        "# Ridge meta-learner\n",
        "meta = RidgeCV(alphas=np.logspace(-3, 2, 50), cv=kf)\n",
        "\n",
        "# Stacking ensemble with out-of-fold blending\n",
        "stack = StackingRegressor(\n",
        "    estimators=[('lgbm', lgbm), ('xgbr', xgbr)],\n",
        "    final_estimator=meta,\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# Model Training\n",
        "# ---------------------------\n",
        "print(\"Training Stacking Regressor...\")\n",
        "stack.fit(X, y)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict & Prepare Submission\n",
        "# ---------------------------\n",
        "print(\"Predicting on test set...\")\n",
        "log_preds = stack.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)\n",
        "final_preds[final_preds < 0] = 0  # ensure no negatives\n",
        "\n",
        "submission = pd.DataFrame({'Id': test_ids, 'HotelValue': final_preds})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created.\")"
      ],
      "metadata": {
        "id": "ZfGFO4RiRfRd",
        "outputId": "b0490514-25b4-4d6a-cda7-3aca24e42a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature matrix shape: (1458, 233)\n",
            "Training Stacking Regressor...\n",
            "Training complete.\n",
            "Predicting on test set...\n",
            "Submission file created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Ridge Regression\n"
      ],
      "metadata": {
        "id": "2OACnl06Tle5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map_ridge_hotel_value.py\n",
        "# MAP estimator via Ridge (Gaussian prior => MAP = Ridge). Uses same preprocessing + GridSearchCV.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from math import sqrt\n",
        "\n",
        "# ====================\n",
        "# CONFIG\n",
        "# ====================\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "TRAIN_PATH = '/content/train.csv'\n",
        "TEST_PATH  = '/content/test.csv'\n",
        "SUB_PATH   = '/content/sample_submission.csv'\n",
        "OUTPUT_PATH = 'submission.csv'\n",
        "\n",
        "# ====================\n",
        "# LOAD\n",
        "# ====================\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SUB_PATH)\n",
        "\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# Remove outliers (kept same logic)\n",
        "outlier_idx = train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index\n",
        "if len(outlier_idx) > 0:\n",
        "    train = train.drop(outlier_idx).reset_index(drop=True)\n",
        "    print(f\"Removed {len(outlier_idx)} outliers.\")\n",
        "\n",
        "# Target (log-transform)\n",
        "y = np.log1p(train['HotelValue'])\n",
        "test_ids = test['Id']\n",
        "\n",
        "train.drop(['HotelValue', 'Id'], axis=1, inplace=True)\n",
        "test.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "# ====================\n",
        "# COMBINE FOR UNIFIED PREPROCESSING\n",
        "# ====================\n",
        "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ====================\n",
        "# FEATURE ENGINEERING (same as before)\n",
        "# ====================\n",
        "print(\"Performing feature engineering...\")\n",
        "if 'PropertyClass' in data.columns:\n",
        "    data['PropertyClass'] = data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area-based features (guard columns)\n",
        "for col in ['BasementTotalSF', 'GroundFloorArea', 'UpperFloorArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalSF'] = data['BasementTotalSF'].fillna(0) + data['GroundFloorArea'].fillna(0) + data['UpperFloorArea'].fillna(0)\n",
        "\n",
        "# Baths\n",
        "for col in ['FullBaths', 'HalfBaths', 'BasementFullBaths', 'BasementHalfBaths']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalBath'] = data['FullBaths'].fillna(0) + 0.5 * data['HalfBaths'].fillna(0) + data['BasementFullBaths'].fillna(0) + 0.5 * data['BasementHalfBaths'].fillna(0)\n",
        "\n",
        "# Porch\n",
        "for col in ['OpenVerandaArea', 'EnclosedVerandaArea', 'SeasonalPorchArea', 'ScreenPorchArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalPorchSF'] = data['OpenVerandaArea'].fillna(0) + data['EnclosedVerandaArea'].fillna(0) + data['SeasonalPorchArea'].fillna(0) + data['ScreenPorchArea'].fillna(0)\n",
        "\n",
        "# Age features\n",
        "for col in ['YearSold', 'ConstructionYear', 'RenovationYear']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = data.get('YearSold', 0)\n",
        "data['HotelAge'] = data['YearSold'].fillna(0) - data['ConstructionYear'].fillna(data['YearSold'].fillna(0))\n",
        "data['RemodAge'] = data['YearSold'].fillna(0) - data['RenovationYear'].fillna(data['YearSold'].fillna(0))\n",
        "\n",
        "# Binary flags\n",
        "data['WasRemodeled'] = (data.get('RenovationYear', data['ConstructionYear']) != data.get('ConstructionYear', data['RenovationYear'])).astype(int)\n",
        "data['IsNew'] = ((data['ConstructionYear'] == data['YearSold']) if ('ConstructionYear' in data.columns and 'YearSold' in data.columns) else 0).astype(int)\n",
        "data['HasPool'] = (data['SwimmingPoolArea'] > 0).astype(int) if 'SwimmingPoolArea' in data.columns else 0\n",
        "data['HasGarage'] = (data['ParkingArea'] > 0).astype(int) if 'ParkingArea' in data.columns else 0\n",
        "data['HasBasement'] = (data['BasementTotalSF'] > 0).astype(int) if 'BasementTotalSF' in data.columns else 0\n",
        "data['HasLounge'] = (data['Lounges'] > 0).astype(int) if 'Lounges' in data.columns else 0\n",
        "\n",
        "# Polynomial & interactions\n",
        "if 'OverallQuality' not in data.columns:\n",
        "    data['OverallQuality'] = 0\n",
        "data['OverallQuality_sq'] = data['OverallQuality']**2\n",
        "data['OverallQuality_cub'] = data['OverallQuality']**3\n",
        "data['OverallQuality_x_TotalSF'] = data['OverallQuality'] * data['TotalSF']\n",
        "data['OverallQuality_x_HotelAge'] = data['OverallQuality'] * data['HotelAge']\n",
        "\n",
        "# Drop weak columns if present\n",
        "drop_cols = [\n",
        "    'ServiceLaneType', 'FacadeType', 'BoundaryFence', 'ExtraFacility',\n",
        "    'UtilityAccess', 'NearbyTransport1', 'NearbyTransport2'\n",
        "]\n",
        "data.drop(columns=[c for c in drop_cols if c in data.columns], inplace=True)\n",
        "\n",
        "# ====================\n",
        "# MISSING VALUE HANDLING (same rules)\n",
        "# ====================\n",
        "print(\"Handling missing values...\")\n",
        "none_cols = [\n",
        "    'PoolQuality', 'BasementHeight', 'BasementCondition', 'BasementExposure',\n",
        "    'BasementFacilityType1', 'BasementFacilityType2', 'ParkingType',\n",
        "    'ParkingFinish', 'ParkingQuality', 'ParkingCondition', 'LoungeQuality'\n",
        "]\n",
        "for col in none_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna('None')\n",
        "\n",
        "mode_cols = ['KitchenQuality', 'PropertyFunctionality', 'ZoningCategory']\n",
        "for col in mode_cols:\n",
        "    if col in data.columns:\n",
        "        if data[col].isnull().any():\n",
        "            data[col] = data[col].fillna(data[col].mode().iloc[0])\n",
        "\n",
        "zero_cols = [\n",
        "    'BasementFacilitySF1', 'BasementFacilitySF2', 'BasementUnfinishedSF',\n",
        "    'BasementTotalSF', 'BasementFullBaths', 'BasementHalfBaths',\n",
        "    'FacadeArea', 'ParkingArea', 'ParkingCapacity'\n",
        "]\n",
        "for col in zero_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna(0)\n",
        "\n",
        "if 'RoadAccessLength' in data.columns and 'District' in data.columns:\n",
        "    data['RoadAccessLength'] = data.groupby('District')['RoadAccessLength'].transform(lambda x: x.fillna(x.median()))\n",
        "    data['RoadAccessLength'].fillna(data['RoadAccessLength'].median(), inplace=True)\n",
        "\n",
        "# final catch-all\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(exclude=[np.number]).columns\n",
        "data[num_cols] = data[num_cols].fillna(0)\n",
        "data[cat_cols] = data[cat_cols].fillna('None')\n",
        "\n",
        "# ====================\n",
        "# ENCODING & SKEW TRANSFORMS\n",
        "# ====================\n",
        "print(\"Encoding categorical features and transforming skewness...\")\n",
        "qual_map = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0}\n",
        "for col in ['ExteriorQuality', 'ExteriorCondition', 'HeatingQuality', 'KitchenQuality',\n",
        "            'LoungeQuality', 'BasementHeight', 'BasementCondition']:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].map(qual_map).fillna(0)\n",
        "\n",
        "if 'CentralAC' in data.columns:\n",
        "    data['CentralAC'] = data['CentralAC'].map({'Y':1, 'N':0}).fillna(0).astype(int)\n",
        "if 'LandSlope' in data.columns:\n",
        "    data['LandSlope'] = data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3)\n",
        "if 'PlotShape' in data.columns:\n",
        "    data['PlotShape'] = data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4)\n",
        "\n",
        "numeric_feats = data.select_dtypes(include=[np.number]).columns\n",
        "skewed = data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "skewed_feats = skewed[skewed.abs() > 0.7].index.tolist()\n",
        "for col in skewed_feats:\n",
        "    if data[col].nunique() > 2:\n",
        "        data[col] = np.log1p(data[col].clip(lower=0))\n",
        "\n",
        "# One-hot encode\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# ====================\n",
        "# SPLIT BACK\n",
        "# ====================\n",
        "X = data.iloc[:len(train), :].copy()\n",
        "X_test = data.iloc[len(train):, :].copy()\n",
        "X, X_test = X.align(X_test, join='inner', axis=1)\n",
        "print(f\"Final X shape: {X.shape}, X_test shape: {X_test.shape}\")\n",
        "\n",
        "# ====================\n",
        "# PIPELINE: VarianceThreshold -> StandardScaler -> Ridge (MAP)\n",
        "# ====================\n",
        "print(\"Setting up Ridge (MAP) pipeline and GridSearchCV...\")\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('var_thresh', VarianceThreshold(threshold=1e-5)),\n",
        "    ('scale', StandardScaler()),\n",
        "    ('reg', Ridge())   # MAP estimator for linear regression with Gaussian prior\n",
        "])\n",
        "\n",
        "# Grid: alpha corresponds to prior strength (bigger alpha => stronger shrinkage)\n",
        "param_grid = {\n",
        "    'reg__alpha': np.logspace(-4, 3, 20),        # from 1e-4 to 1e3\n",
        "    'reg__fit_intercept': [True, False],\n",
        "    'reg__solver': ['auto', 'svd', 'cholesky']   # stable solvers\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',   # on log1p(target)\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "print(\"Running GridSearchCV for MAP (Ridge) — tuning alpha (prior strength) and solver...\")\n",
        "grid.fit(X, y)\n",
        "\n",
        "best_rmse = -grid.best_score_\n",
        "print(\"Best CV RMSE (log-target):\", best_rmse)\n",
        "print(\"Best params (MAP via Ridge):\", grid.best_params_)\n",
        "\n",
        "# Use best model to predict\n",
        "best_model = grid.best_estimator_\n",
        "log_preds = best_model.predict(X_test)\n",
        "preds = np.expm1(log_preds)\n",
        "preds[preds < 0] = 0.0\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'Id': test_ids, 'HotelValue': preds})\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"✅ Submission saved to {OUTPUT_PATH}\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "id": "ZPGvEzKTTn0n",
        "outputId": "b5b98a51-0fc9-47e7-c044-e57300ffce03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1200, 81), Test shape: (260, 80)\n",
            "Removed 2 outliers.\n",
            "Performing feature engineering...\n",
            "Handling missing values...\n",
            "Encoding categorical features and transforming skewness...\n",
            "Final X shape: (1198, 235), X_test shape: (260, 235)\n",
            "Setting up Ridge (MAP) pipeline and GridSearchCV...\n",
            "Running GridSearchCV for MAP (Ridge) — tuning alpha (prior strength) and solver...\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "Best CV RMSE (log-target): 0.11967611377762848\n",
            "Best params (MAP via Ridge): {'reg__alpha': np.float64(428.1332398719387), 'reg__fit_intercept': True, 'reg__solver': 'auto'}\n",
            "✅ Submission saved to submission.csv\n",
            "     Id     HotelValue\n",
            "0   893  145320.034031\n",
            "1  1106  317968.522646\n",
            "2   414  103249.406448\n",
            "3   523  167375.626388\n",
            "4  1037  311081.887484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAP Bayesian Regression"
      ],
      "metadata": {
        "id": "2DnyPpyHUkOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bayesian_conjugate_hotel_value.py\n",
        "# Bayesian linear regression with conjugate Gaussian prior (closed-form posterior)\n",
        "# Preserves your preprocessing + GridSearchCV for hyperparameter tuning.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# ====================\n",
        "# Custom estimator: Conjugate Bayesian Linear Regressor (scikit-learn style)\n",
        "# ====================\n",
        "class ConjugateBayesRegressor(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"\n",
        "    Bayesian linear regression with conjugate Gaussian prior:\n",
        "      prior: w ~ N(0, alpha^{-1} I)\n",
        "      noise: y = X w + eps, eps ~ N(0, sigma2 I)\n",
        "    Fits closed-form posterior mean (and optionally posterior covariance).\n",
        "    Params (for GridSearchCV): alpha_prior (prior precision), sigma2 (noise variance),\n",
        "    fit_intercept (bool).\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha_prior=1.0, sigma2=1.0, fit_intercept=True, jitter=1e-8):\n",
        "        self.alpha_prior = alpha_prior\n",
        "        self.sigma2 = sigma2\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.jitter = jitter  # numerical stability\n",
        "        # attributes set in fit:\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = 0.0\n",
        "        self.posterior_cov_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        y = np.asarray(y, dtype=float)\n",
        "\n",
        "        # Handle intercept by centering data if requested\n",
        "        if self.fit_intercept:\n",
        "            self.X_mean_ = X.mean(axis=0)\n",
        "            self.y_mean_ = y.mean()\n",
        "            Xc = X - self.X_mean_\n",
        "            yc = y - self.y_mean_\n",
        "        else:\n",
        "            self.X_mean_ = np.zeros(X.shape[1], dtype=float)\n",
        "            self.y_mean_ = 0.0\n",
        "            Xc = X\n",
        "            yc = y\n",
        "\n",
        "        # Compute sufficient statistics\n",
        "        XtX = Xc.T.dot(Xc)           # shape (p, p)\n",
        "        Xty = Xc.T.dot(yc)           # shape (p,)\n",
        "\n",
        "        # posterior precision: (XtX / sigma2) + alpha_prior * I\n",
        "        p = XtX.shape[0]\n",
        "        precision = XtX / max(self.sigma2, 1e-12)\n",
        "        precision.flat[::p+1] += self.alpha_prior  # add alpha_prior to diagonal\n",
        "\n",
        "        # add jitter for numerical stability\n",
        "        precision += np.eye(p) * self.jitter\n",
        "\n",
        "        # posterior mean = precision^{-1} * (X^T y / sigma2)\n",
        "        rhs = Xty / max(self.sigma2, 1e-12)\n",
        "        # solve precision * coef = rhs\n",
        "        coef = np.linalg.solve(precision, rhs)\n",
        "\n",
        "        # optionally compute posterior covariance (could be large)\n",
        "        # posterior_cov = precision^{-1}\n",
        "        try:\n",
        "            # compute inverse via solve for identity where cost is acceptable\n",
        "            posterior_cov = np.linalg.inv(precision)\n",
        "        except np.linalg.LinAlgError:\n",
        "            posterior_cov = None\n",
        "\n",
        "        # set attributes\n",
        "        self.coef_ = coef\n",
        "        self.posterior_cov_ = posterior_cov\n",
        "        if self.fit_intercept:\n",
        "            self.intercept_ = self.y_mean_ - self.X_mean_.dot(self.coef_)\n",
        "        else:\n",
        "            self.intercept_ = 0.0\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        return X.dot(self.coef_) + self.intercept_\n",
        "\n",
        "    # scikit-learn compatibility (optional)\n",
        "    def get_params(self, deep=True):\n",
        "        return {\"alpha_prior\": self.alpha_prior, \"sigma2\": self.sigma2, \"fit_intercept\": self.fit_intercept, \"jitter\": self.jitter}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        for k, v in params.items():\n",
        "            setattr(self, k, v)\n",
        "        return self\n",
        "\n",
        "# ====================\n",
        "# CONFIG\n",
        "# ====================\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "TRAIN_PATH = '/content/train.csv'\n",
        "TEST_PATH  = '/content/test.csv'\n",
        "SUB_PATH   = '/content/sample_submission.csv'\n",
        "OUTPUT_PATH = 'submission.csv'\n",
        "\n",
        "# ====================\n",
        "# LOAD DATA\n",
        "# ====================\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SUB_PATH)\n",
        "\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# remove outliers as you did before\n",
        "outlier_idx = train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index\n",
        "if len(outlier_idx) > 0:\n",
        "    train = train.drop(outlier_idx).reset_index(drop=True)\n",
        "    print(f\"Removed {len(outlier_idx)} outliers.\")\n",
        "\n",
        "# target & ids\n",
        "y = np.log1p(train['HotelValue'])\n",
        "test_ids = test['Id']\n",
        "\n",
        "train.drop(['HotelValue', 'Id'], axis=1, inplace=True)\n",
        "test.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "# ====================\n",
        "# COMBINE FOR UNIFIED PREPROCESSING\n",
        "# ====================\n",
        "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ====================\n",
        "# FEATURE ENGINEERING (keeps your transforms)\n",
        "# ====================\n",
        "print(\"Performing feature engineering...\")\n",
        "\n",
        "if 'PropertyClass' in data.columns:\n",
        "    data['PropertyClass'] = data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area-based features\n",
        "for col in ['BasementTotalSF', 'GroundFloorArea', 'UpperFloorArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalSF'] = data['BasementTotalSF'].fillna(0) + data['GroundFloorArea'].fillna(0) + data['UpperFloorArea'].fillna(0)\n",
        "\n",
        "# Baths\n",
        "for col in ['FullBaths', 'HalfBaths', 'BasementFullBaths', 'BasementHalfBaths']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalBath'] = data['FullBaths'].fillna(0) + 0.5 * data['HalfBaths'].fillna(0) + data['BasementFullBaths'].fillna(0) + 0.5 * data['BasementHalfBaths'].fillna(0)\n",
        "\n",
        "# Porch\n",
        "for col in ['OpenVerandaArea', 'EnclosedVerandaArea', 'SeasonalPorchArea', 'ScreenPorchArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalPorchSF'] = data['OpenVerandaArea'].fillna(0) + data['EnclosedVerandaArea'].fillna(0) + data['SeasonalPorchArea'].fillna(0) + data['ScreenPorchArea'].fillna(0)\n",
        "\n",
        "# Age features\n",
        "for col in ['YearSold', 'ConstructionYear', 'RenovationYear']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = data.get('YearSold', 0)\n",
        "data['HotelAge'] = data['YearSold'].fillna(0) - data['ConstructionYear'].fillna(data['YearSold'].fillna(0))\n",
        "data['RemodAge'] = data['YearSold'].fillna(0) - data['RenovationYear'].fillna(data['YearSold'].fillna(0))\n",
        "\n",
        "# Binary flags\n",
        "data['WasRemodeled'] = (data.get('RenovationYear', data['ConstructionYear']) != data.get('ConstructionYear', data['RenovationYear'])).astype(int)\n",
        "data['IsNew'] = (data['ConstructionYear'] == data['YearSold']).astype(int) if ('ConstructionYear' in data.columns and 'YearSold' in data.columns) else 0\n",
        "data['HasPool'] = (data['SwimmingPoolArea'] > 0).astype(int) if 'SwimmingPoolArea' in data.columns else 0\n",
        "data['HasGarage'] = (data['ParkingArea'] > 0).astype(int) if 'ParkingArea' in data.columns else 0\n",
        "data['HasBasement'] = (data['BasementTotalSF'] > 0).astype(int) if 'BasementTotalSF' in data.columns else 0\n",
        "data['HasLounge'] = (data['Lounges'] > 0).astype(int) if 'Lounges' in data.columns else 0\n",
        "\n",
        "# Polynomial / interaction terms\n",
        "if 'OverallQuality' not in data.columns:\n",
        "    data['OverallQuality'] = 0\n",
        "data['OverallQuality_sq'] = data['OverallQuality']**2\n",
        "data['OverallQuality_cub'] = data['OverallQuality']**3\n",
        "data['OverallQuality_x_TotalSF'] = data['OverallQuality'] * data['TotalSF']\n",
        "data['OverallQuality_x_HotelAge'] = data['OverallQuality'] * data['HotelAge']\n",
        "\n",
        "# Drop weak columns if present\n",
        "drop_cols = [\n",
        "    'ServiceLaneType', 'FacadeType', 'BoundaryFence', 'ExtraFacility',\n",
        "    'UtilityAccess', 'NearbyTransport1', 'NearbyTransport2'\n",
        "]\n",
        "data.drop(columns=[c for c in drop_cols if c in data.columns], inplace=True)\n",
        "\n",
        "# ====================\n",
        "# MISSING VALUE HANDLING\n",
        "# ====================\n",
        "print(\"Handling missing values...\")\n",
        "none_cols = [\n",
        "    'PoolQuality', 'BasementHeight', 'BasementCondition', 'BasementExposure',\n",
        "    'BasementFacilityType1', 'BasementFacilityType2', 'ParkingType',\n",
        "    'ParkingFinish', 'ParkingQuality', 'ParkingCondition', 'LoungeQuality'\n",
        "]\n",
        "for col in none_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna('None')\n",
        "\n",
        "mode_cols = ['KitchenQuality', 'PropertyFunctionality', 'ZoningCategory']\n",
        "for col in mode_cols:\n",
        "    if col in data.columns:\n",
        "        if data[col].isnull().any():\n",
        "            data[col] = data[col].fillna(data[col].mode().iloc[0])\n",
        "\n",
        "zero_cols = [\n",
        "    'BasementFacilitySF1', 'BasementFacilitySF2', 'BasementUnfinishedSF',\n",
        "    'BasementTotalSF', 'BasementFullBaths', 'BasementHalfBaths',\n",
        "    'FacadeArea', 'ParkingArea', 'ParkingCapacity'\n",
        "]\n",
        "for col in zero_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna(0)\n",
        "\n",
        "if 'RoadAccessLength' in data.columns and 'District' in data.columns:\n",
        "    data['RoadAccessLength'] = data.groupby('District')['RoadAccessLength'].transform(lambda x: x.fillna(x.median()))\n",
        "    data['RoadAccessLength'].fillna(data['RoadAccessLength'].median(), inplace=True)\n",
        "\n",
        "# Catch-all\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(exclude=[np.number]).columns\n",
        "data[num_cols] = data[num_cols].fillna(0)\n",
        "data[cat_cols] = data[cat_cols].fillna('None')\n",
        "\n",
        "# ====================\n",
        "# ENCODING & SKEW TRANSFORMS\n",
        "# ====================\n",
        "print(\"Encoding categorical features and transforming skewness...\")\n",
        "qual_map = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0}\n",
        "for col in ['ExteriorQuality', 'ExteriorCondition', 'HeatingQuality', 'KitchenQuality',\n",
        "            'LoungeQuality', 'BasementHeight', 'BasementCondition']:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].map(qual_map).fillna(0)\n",
        "\n",
        "if 'CentralAC' in data.columns:\n",
        "    data['CentralAC'] = data['CentralAC'].map({'Y':1, 'N':0}).fillna(0).astype(int)\n",
        "if 'LandSlope' in data.columns:\n",
        "    data['LandSlope'] = data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3)\n",
        "if 'PlotShape' in data.columns:\n",
        "    data['PlotShape'] = data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4)\n",
        "\n",
        "numeric_feats = data.select_dtypes(include=[np.number]).columns\n",
        "skewed = data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "skewed_feats = skewed[skewed.abs() > 0.7].index.tolist()\n",
        "for col in skewed_feats:\n",
        "    if data[col].nunique() > 2:\n",
        "        data[col] = np.log1p(data[col].clip(lower=0))\n",
        "\n",
        "# One-hot encode remaining categoricals\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# ====================\n",
        "# FINAL SPLIT\n",
        "# ====================\n",
        "X = data.iloc[:len(train), :].copy()\n",
        "X_test = data.iloc[len(train):, :].copy()\n",
        "# Align columns\n",
        "X, X_test = X.align(X_test, join='inner', axis=1)\n",
        "print(f\"Final X shape: {X.shape}, X_test shape: {X_test.shape}\")\n",
        "\n",
        "# ====================\n",
        "# PIPELINE and GRIDSEARCH (tune conjugate prior hyperparameters)\n",
        "# ====================\n",
        "print(\"Setting up pipeline and GridSearchCV for conjugate-prior Bayesian regression...\")\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('var_thresh', VarianceThreshold(threshold=1e-5)),\n",
        "    ('scale', StandardScaler()),\n",
        "    ('reg', ConjugateBayesRegressor())   # our custom estimator\n",
        "])\n",
        "\n",
        "# Grid: tune prior precision (alpha_prior), noise variance (sigma2), and fit_intercept.\n",
        "param_grid = {\n",
        "    'reg__alpha_prior': [1e-6, 1e-4, 1e-2, 1e-1, 1.0, 10.0, 100.0],\n",
        "    'reg__sigma2':      [1e-3, 1e-2, 1e-1, 1.0, 10.0, 100.0],\n",
        "    'reg__fit_intercept':[True, False]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "print(\"Running GridSearchCV (this will tune conjugate prior hyperparameters)...\")\n",
        "start_time = time.time()\n",
        "grid.fit(X, y)\n",
        "elapsed = time.time() - start_time\n",
        "\n",
        "best_rmse = -grid.best_score_\n",
        "print(f\"GridSearchCV finished in {elapsed:.1f}s\")\n",
        "print(\"Best CV RMSE (log-target):\", best_rmse)\n",
        "print(\"Best params (conjugate-prior bayes):\", grid.best_params_)\n",
        "\n",
        "# final model and predictions\n",
        "best_model = grid.best_estimator_\n",
        "log_preds = best_model.predict(X_test)\n",
        "preds = np.expm1(log_preds)\n",
        "preds[preds < 0] = 0.0\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'Id': test_ids, 'HotelValue': preds})\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"✅ Submission saved to {OUTPUT_PATH}\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "id": "EWo6thBVUmF1",
        "outputId": "b86f9084-95d0-4eca-d8cf-d8bb5db4ae8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1200, 81), Test shape: (260, 80)\n",
            "Removed 2 outliers.\n",
            "Performing feature engineering...\n",
            "Handling missing values...\n",
            "Encoding categorical features and transforming skewness...\n",
            "Final X shape: (1198, 235), X_test shape: (260, 235)\n",
            "Setting up pipeline and GridSearchCV for conjugate-prior Bayesian regression...\n",
            "Running GridSearchCV (this will tune conjugate prior hyperparameters)...\n",
            "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
            "GridSearchCV finished in 10.7s\n",
            "Best CV RMSE (log-target): 0.12144326406040104\n",
            "Best params (conjugate-prior bayes): {'reg__alpha_prior': 1.0, 'reg__fit_intercept': True, 'reg__sigma2': 100.0}\n",
            "✅ Submission saved to submission.csv\n",
            "     Id     HotelValue\n",
            "0   893  145911.180669\n",
            "1  1106  326261.781096\n",
            "2   414  104342.323069\n",
            "3   523  171838.562488\n",
            "4  1037  311483.314575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "NGcffHPQVVGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision_tree_only_hotel_value.py\n",
        "# Uses scikit-learn DecisionTreeRegressor + GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.metrics import make_scorer\n",
        "from math import sqrt\n",
        "\n",
        "# ====================\n",
        "# CONFIG\n",
        "# ====================\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "TRAIN_PATH = '/content/train.csv'\n",
        "TEST_PATH  = '/content/test.csv'\n",
        "SUB_PATH   = '/content/sample_submission.csv'\n",
        "OUTPUT_PATH = 'submission.csv'\n",
        "\n",
        "# ====================\n",
        "# LOAD\n",
        "# ====================\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SUB_PATH)\n",
        "\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# Remove outliers (same logic you used)\n",
        "outlier_idx = train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index\n",
        "if len(outlier_idx) > 0:\n",
        "    train = train.drop(outlier_idx).reset_index(drop=True)\n",
        "    print(f\"Removed {len(outlier_idx)} outliers.\")\n",
        "\n",
        "# Target: log-transform as before (tree can handle either, but we keep consistency)\n",
        "y = np.log1p(train['HotelValue'])\n",
        "test_ids = test['Id']\n",
        "\n",
        "train.drop(['HotelValue', 'Id'], axis=1, inplace=True)\n",
        "test.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "# ====================\n",
        "# COMBINE FOR PROCESSING\n",
        "# ====================\n",
        "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ====================\n",
        "# FEATURE ENGINEERING (preserved)\n",
        "# ====================\n",
        "print(\"Performing feature engineering...\")\n",
        "if 'PropertyClass' in data.columns:\n",
        "    data['PropertyClass'] = data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area-based\n",
        "for col in ['BasementTotalSF', 'GroundFloorArea', 'UpperFloorArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalSF'] = data['BasementTotalSF'].fillna(0) + data['GroundFloorArea'].fillna(0) + data['UpperFloorArea'].fillna(0)\n",
        "\n",
        "# Baths\n",
        "for col in ['FullBaths', 'HalfBaths', 'BasementFullBaths', 'BasementHalfBaths']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalBath'] = data['FullBaths'].fillna(0) + 0.5*data['HalfBaths'].fillna(0) + data['BasementFullBaths'].fillna(0) + 0.5*data['BasementHalfBaths'].fillna(0)\n",
        "\n",
        "# Porch\n",
        "for col in ['OpenVerandaArea', 'EnclosedVerandaArea', 'SeasonalPorchArea', 'ScreenPorchArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalPorchSF'] = data['OpenVerandaArea'].fillna(0) + data['EnclosedVerandaArea'].fillna(0) + data['SeasonalPorchArea'].fillna(0) + data['ScreenPorchArea'].fillna(0)\n",
        "\n",
        "# Age features\n",
        "for col in ['YearSold','ConstructionYear','RenovationYear']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = data['YearSold'] if 'YearSold' in data.columns else 0\n",
        "data['HotelAge'] = data['YearSold'].fillna(0) - data['ConstructionYear'].fillna(data['YearSold'].fillna(0))\n",
        "data['RemodAge'] = data['YearSold'].fillna(0) - data['RenovationYear'].fillna(data['YearSold'].fillna(0))\n",
        "\n",
        "# Binary flags\n",
        "data['WasRemodeled'] = (data.get('RenovationYear', data['ConstructionYear']) != data.get('ConstructionYear', data['RenovationYear'])).astype(int)\n",
        "data['IsNew'] = (data['ConstructionYear'] == data['YearSold']).astype(int) if ('ConstructionYear' in data.columns and 'YearSold' in data.columns) else 0\n",
        "data['HasPool'] = (data['SwimmingPoolArea'] > 0).astype(int) if 'SwimmingPoolArea' in data.columns else 0\n",
        "data['HasGarage'] = (data['ParkingArea'] > 0).astype(int) if 'ParkingArea' in data.columns else 0\n",
        "data['HasBasement'] = (data['BasementTotalSF'] > 0).astype(int) if 'BasementTotalSF' in data.columns else 0\n",
        "data['HasLounge'] = (data['Lounges'] > 0).astype(int) if 'Lounges' in data.columns else 0\n",
        "\n",
        "# Polynomial / interactions\n",
        "if 'OverallQuality' not in data.columns:\n",
        "    data['OverallQuality'] = 0\n",
        "data['OverallQuality_sq'] = data['OverallQuality']**2\n",
        "data['OverallQuality_cub'] = data['OverallQuality']**3\n",
        "data['OverallQuality_x_TotalSF'] = data['OverallQuality'] * data['TotalSF']\n",
        "data['OverallQuality_x_HotelAge'] = data['OverallQuality'] * data['HotelAge']\n",
        "\n",
        "# Drop certain weak columns if present\n",
        "drop_cols = [\n",
        "    'ServiceLaneType', 'FacadeType', 'BoundaryFence', 'ExtraFacility',\n",
        "    'UtilityAccess', 'NearbyTransport1', 'NearbyTransport2'\n",
        "]\n",
        "data.drop(columns=[c for c in drop_cols if c in data.columns], inplace=True)\n",
        "\n",
        "# ====================\n",
        "# MISSING VALUE HANDLING\n",
        "# ====================\n",
        "print(\"Handling missing values...\")\n",
        "none_cols = [\n",
        "    'PoolQuality', 'BasementHeight', 'BasementCondition', 'BasementExposure',\n",
        "    'BasementFacilityType1', 'BasementFacilityType2', 'ParkingType',\n",
        "    'ParkingFinish', 'ParkingQuality', 'ParkingCondition', 'LoungeQuality'\n",
        "]\n",
        "for col in none_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna('None')\n",
        "\n",
        "mode_cols = ['KitchenQuality', 'PropertyFunctionality', 'ZoningCategory']\n",
        "for col in mode_cols:\n",
        "    if col in data.columns:\n",
        "        if data[col].isnull().any():\n",
        "            data[col] = data[col].fillna(data[col].mode().iloc[0])\n",
        "\n",
        "zero_cols = [\n",
        "    'BasementFacilitySF1', 'BasementFacilitySF2', 'BasementUnfinishedSF',\n",
        "    'BasementTotalSF', 'BasementFullBaths', 'BasementHalfBaths',\n",
        "    'FacadeArea', 'ParkingArea', 'ParkingCapacity'\n",
        "]\n",
        "for col in zero_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna(0)\n",
        "\n",
        "if 'RoadAccessLength' in data.columns and 'District' in data.columns:\n",
        "    data['RoadAccessLength'] = data.groupby('District')['RoadAccessLength'].transform(lambda x: x.fillna(x.median()))\n",
        "    data['RoadAccessLength'].fillna(data['RoadAccessLength'].median(), inplace=True)\n",
        "\n",
        "# Catch-all fills\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(exclude=[np.number]).columns\n",
        "data[num_cols] = data[num_cols].fillna(0)\n",
        "data[cat_cols] = data[cat_cols].fillna('None')\n",
        "\n",
        "# ====================\n",
        "# ENCODING & SKEW TRANSFORMS\n",
        "# ====================\n",
        "print(\"Encoding categorical features and transforming skewness...\")\n",
        "qual_map = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0}\n",
        "for col in ['ExteriorQuality', 'ExteriorCondition', 'HeatingQuality', 'KitchenQuality',\n",
        "            'LoungeQuality', 'BasementHeight', 'BasementCondition']:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].map(qual_map).fillna(0)\n",
        "\n",
        "if 'CentralAC' in data.columns:\n",
        "    data['CentralAC'] = data['CentralAC'].map({'Y':1, 'N':0}).fillna(0).astype(int)\n",
        "if 'LandSlope' in data.columns:\n",
        "    data['LandSlope'] = data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3)\n",
        "if 'PlotShape' in data.columns:\n",
        "    data['PlotShape'] = data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4)\n",
        "\n",
        "# Log-transform skewed numerics (avoid booleans)\n",
        "numeric_feats = data.select_dtypes(include=[np.number]).columns\n",
        "skewed = data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "skewed_feats = skewed[skewed.abs() > 0.7].index.tolist()\n",
        "for col in skewed_feats:\n",
        "    if data[col].nunique() > 2:\n",
        "        data[col] = np.log1p(data[col].clip(lower=0))\n",
        "\n",
        "# One-hot encode remaining categoricals\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# ====================\n",
        "# SPLIT BACK\n",
        "# ====================\n",
        "X = data.iloc[:len(train), :].copy()\n",
        "X_test = data.iloc[len(train):, :].copy()\n",
        "X, X_test = X.align(X_test, join='inner', axis=1)\n",
        "print(f\"Final X shape: {X.shape}, X_test shape: {X_test.shape}\")\n",
        "\n",
        "# ====================\n",
        "# DECISION TREE PIPELINE + GRIDSEARCH\n",
        "# ====================\n",
        "print(\"Setting up DecisionTreeRegressor pipeline and GridSearchCV...\")\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('var_thresh', VarianceThreshold(threshold=1e-5)),   # remove near-constant features\n",
        "    ('dt', DecisionTreeRegressor(random_state=SEED))\n",
        "])\n",
        "\n",
        "# Grid for DecisionTreeRegressor\n",
        "param_grid = {\n",
        "    'dt__criterion': ['squared_error', 'friedman_mse'],  # 'mse' deprecated alias; sklearn uses squared_error\n",
        "    'dt__max_depth': [None, 6, 10, 15, 25],\n",
        "    'dt__min_samples_split': [2, 5, 10, 20],\n",
        "    'dt__min_samples_leaf': [1, 2, 4, 8],\n",
        "    'dt__max_features': [None, 'sqrt', 'log2', 0.3, 0.5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',  # on log target\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "print(\"Running GridSearchCV — this may take a while depending on grid size and CPU...\")\n",
        "grid.fit(X, y)\n",
        "\n",
        "best_rmse = -grid.best_score_\n",
        "print(\"Best CV RMSE (log-target):\", best_rmse)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "\n",
        "# Predict (GridSearchCV already refit on full train)\n",
        "best_model = grid.best_estimator_\n",
        "log_preds = best_model.predict(X_test)\n",
        "preds = np.expm1(log_preds)\n",
        "preds[preds < 0] = 0.0\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'Id': test_ids, 'HotelValue': preds})\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"✅ Submission saved to {OUTPUT_PATH}\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "id": "oqCcbOcBWMCX",
        "outputId": "a0fd6f41-b146-4f4b-cb0f-ba656fc01d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1200, 81), Test shape: (260, 80)\n",
            "Removed 2 outliers.\n",
            "Performing feature engineering...\n",
            "Handling missing values...\n",
            "Encoding categorical features and transforming skewness...\n",
            "Final X shape: (1198, 235), X_test shape: (260, 235)\n",
            "Setting up DecisionTreeRegressor pipeline and GridSearchCV...\n",
            "Running GridSearchCV — this may take a while depending on grid size and CPU...\n",
            "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n",
            "Best CV RMSE (log-target): 0.17078003100334918\n",
            "Best params: {'dt__criterion': 'friedman_mse', 'dt__max_depth': 10, 'dt__max_features': None, 'dt__min_samples_leaf': 8, 'dt__min_samples_split': 20}\n",
            "✅ Submission saved to submission.csv\n",
            "     Id     HotelValue\n",
            "0   893  145925.782517\n",
            "1  1106  302159.123847\n",
            "2   414  123534.557386\n",
            "3   523  181440.246612\n",
            "4  1037  290843.688764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLE"
      ],
      "metadata": {
        "id": "RdoONbI5YT99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mle_linear_regression_with_gridsearch.py\n",
        "# Use MLE (LinearRegression = OLS) + GridSearchCV, preserving your preprocessing pipeline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ================\n",
        "# CONFIG\n",
        "# ================\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "np.random.seed(SEED)\n",
        "\n",
        "TRAIN_PATH = '/content/train.csv'\n",
        "TEST_PATH  = '/content/test.csv'\n",
        "SUB_PATH   = '/content/sample_submission.csv'\n",
        "OUTPUT_PATH = 'submission.csv'\n",
        "\n",
        "# ================\n",
        "# LOAD\n",
        "# ================\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SUB_PATH)\n",
        "\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# Remove outliers (same rule you used)\n",
        "outlier_idx = train[(train['UsableArea'] > 4000) & (train['HotelValue'] < 300000)].index\n",
        "if len(outlier_idx) > 0:\n",
        "    train = train.drop(outlier_idx).reset_index(drop=True)\n",
        "    print(f\"Removed {len(outlier_idx)} outliers.\")\n",
        "\n",
        "# Target: log transform (keep same target transform)\n",
        "y = np.log1p(train['HotelValue'])\n",
        "test_ids = test['Id']\n",
        "\n",
        "train.drop(['HotelValue', 'Id'], axis=1, inplace=True)\n",
        "test.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "# ================\n",
        "# COMBINE FOR UNIFIED PREPROCESSING\n",
        "# ================\n",
        "data = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ================\n",
        "# FEATURE ENGINEERING (kept identical to your prior pipeline)\n",
        "# ================\n",
        "print(\"Performing feature engineering...\")\n",
        "\n",
        "if 'PropertyClass' in data.columns:\n",
        "    data['PropertyClass'] = data['PropertyClass'].astype(str)\n",
        "\n",
        "# Area-based\n",
        "for col in ['BasementTotalSF', 'GroundFloorArea', 'UpperFloorArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalSF'] = data['BasementTotalSF'].fillna(0) + data['GroundFloorArea'].fillna(0) + data['UpperFloorArea'].fillna(0)\n",
        "\n",
        "# Baths\n",
        "for col in ['FullBaths', 'HalfBaths', 'BasementFullBaths', 'BasementHalfBaths']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalBath'] = (\n",
        "    data['FullBaths'].fillna(0) + 0.5 * data['HalfBaths'].fillna(0)\n",
        "    + data['BasementFullBaths'].fillna(0) + 0.5 * data['BasementHalfBaths'].fillna(0)\n",
        ")\n",
        "\n",
        "# Porches\n",
        "for col in ['OpenVerandaArea', 'EnclosedVerandaArea', 'SeasonalPorchArea', 'ScreenPorchArea']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = 0\n",
        "data['TotalPorchSF'] = (\n",
        "    data['OpenVerandaArea'].fillna(0) + data['EnclosedVerandaArea'].fillna(0)\n",
        "    + data['SeasonalPorchArea'].fillna(0) + data['ScreenPorchArea'].fillna(0)\n",
        ")\n",
        "\n",
        "# Age features\n",
        "for col in ['YearSold','ConstructionYear','RenovationYear']:\n",
        "    if col not in data.columns:\n",
        "        data[col] = data.get('YearSold', 0)\n",
        "data['HotelAge'] = data['YearSold'].fillna(0) - data['ConstructionYear'].fillna(data['YearSold'].fillna(0))\n",
        "data['RemodAge'] = data['YearSold'].fillna(0) - data['RenovationYear'].fillna(data['YearSold'].fillna(0))\n",
        "\n",
        "# Binary flags\n",
        "data['WasRemodeled'] = (data.get('RenovationYear', data['ConstructionYear']) != data.get('ConstructionYear', data['RenovationYear'])).astype(int)\n",
        "data['IsNew'] = (data['ConstructionYear'] == data['YearSold']).astype(int) if ('ConstructionYear' in data.columns and 'YearSold' in data.columns) else 0\n",
        "data['HasPool'] = (data['SwimmingPoolArea'] > 0).astype(int) if 'SwimmingPoolArea' in data.columns else 0\n",
        "data['HasGarage'] = (data['ParkingArea'] > 0).astype(int) if 'ParkingArea' in data.columns else 0\n",
        "data['HasBasement'] = (data['BasementTotalSF'] > 0).astype(int) if 'BasementTotalSF' in data.columns else 0\n",
        "data['HasLounge'] = (data['Lounges'] > 0).astype(int) if 'Lounges' in data.columns else 0\n",
        "\n",
        "# Polynomial & interactions\n",
        "if 'OverallQuality' not in data.columns:\n",
        "    data['OverallQuality'] = 0\n",
        "data['OverallQuality_sq'] = data['OverallQuality']**2\n",
        "data['OverallQuality_cub'] = data['OverallQuality']**3\n",
        "data['OverallQuality_x_TotalSF'] = data['OverallQuality'] * data['TotalSF']\n",
        "data['OverallQuality_x_HotelAge'] = data['OverallQuality'] * data['HotelAge']\n",
        "\n",
        "# Drop weak columns if present\n",
        "drop_cols = [\n",
        "    'ServiceLaneType', 'FacadeType', 'BoundaryFence', 'ExtraFacility',\n",
        "    'UtilityAccess', 'NearbyTransport1', 'NearbyTransport2'\n",
        "]\n",
        "data.drop(columns=[c for c in drop_cols if c in data.columns], inplace=True)\n",
        "\n",
        "# ================\n",
        "# MISSING VALUE HANDLING (same rules)\n",
        "# ================\n",
        "print(\"Handling missing values...\")\n",
        "none_cols = [\n",
        "    'PoolQuality', 'BasementHeight', 'BasementCondition', 'BasementExposure',\n",
        "    'BasementFacilityType1', 'BasementFacilityType2', 'ParkingType',\n",
        "    'ParkingFinish', 'ParkingQuality', 'ParkingCondition', 'LoungeQuality'\n",
        "]\n",
        "for col in none_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna('None')\n",
        "\n",
        "mode_cols = ['KitchenQuality', 'PropertyFunctionality', 'ZoningCategory']\n",
        "for col in mode_cols:\n",
        "    if col in data.columns:\n",
        "        if data[col].isnull().any():\n",
        "            data[col] = data[col].fillna(data[col].mode().iloc[0])\n",
        "\n",
        "zero_cols = [\n",
        "    'BasementFacilitySF1', 'BasementFacilitySF2', 'BasementUnfinishedSF',\n",
        "    'BasementTotalSF', 'BasementFullBaths', 'BasementHalfBaths',\n",
        "    'FacadeArea', 'ParkingArea', 'ParkingCapacity'\n",
        "]\n",
        "for col in zero_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].fillna(0)\n",
        "\n",
        "if 'RoadAccessLength' in data.columns and 'District' in data.columns:\n",
        "    data['RoadAccessLength'] = data.groupby('District')['RoadAccessLength'].transform(lambda x: x.fillna(x.median()))\n",
        "    data['RoadAccessLength'].fillna(data['RoadAccessLength'].median(), inplace=True)\n",
        "\n",
        "# Final catch-all\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = data.select_dtypes(exclude=[np.number]).columns\n",
        "data[num_cols] = data[num_cols].fillna(0)\n",
        "data[cat_cols] = data[cat_cols].fillna('None')\n",
        "\n",
        "# ================\n",
        "# ENCODING & TRANSFORMS\n",
        "# ================\n",
        "print(\"Encoding categorical features and transforming skewness...\")\n",
        "qual_map = {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'None':0}\n",
        "for col in ['ExteriorQuality', 'ExteriorCondition', 'HeatingQuality', 'KitchenQuality',\n",
        "            'LoungeQuality', 'BasementHeight', 'BasementCondition']:\n",
        "    if col in data.columns:\n",
        "        data[col] = data[col].map(qual_map).fillna(0)\n",
        "\n",
        "if 'CentralAC' in data.columns:\n",
        "    data['CentralAC'] = data['CentralAC'].map({'Y':1, 'N':0}).fillna(0).astype(int)\n",
        "if 'LandSlope' in data.columns:\n",
        "    data['LandSlope'] = data['LandSlope'].map({'Gtl':3,'Mod':2,'Sev':1}).fillna(3)\n",
        "if 'PlotShape' in data.columns:\n",
        "    data['PlotShape'] = data['PlotShape'].map({'Reg':4,'IR1':3,'IR2':2,'IR3':1}).fillna(4)\n",
        "\n",
        "numeric_feats = data.select_dtypes(include=[np.number]).columns\n",
        "skewed = data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "skewed_feats = skewed[skewed.abs() > 0.7].index.tolist()\n",
        "for col in skewed_feats:\n",
        "    if data[col].nunique() > 2:\n",
        "        data[col] = np.log1p(data[col].clip(lower=0))\n",
        "\n",
        "# One-hot encode\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# ================\n",
        "# FINAL SPLIT\n",
        "# ================\n",
        "X = data.iloc[:len(train), :].copy()\n",
        "X_test = data.iloc[len(train):, :].copy()\n",
        "\n",
        "# Align columns\n",
        "X, X_test = X.align(X_test, join='inner', axis=1)\n",
        "print(f\"Final X shape: {X.shape}, X_test shape: {X_test.shape}\")\n",
        "\n",
        "# ================\n",
        "# PIPELINE & GRIDSEARCH (LinearRegression = MLE)\n",
        "# ================\n",
        "print(\"Setting up LinearRegression (MLE) pipeline and GridSearchCV...\")\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('var_thresh', VarianceThreshold()),   # tune threshold in grid\n",
        "    ('scale', StandardScaler()),\n",
        "    ('pca', PCA()),                        # optional dimensionality reduction\n",
        "    ('reg', LinearRegression())\n",
        "])\n",
        "\n",
        "# Grid over preprocessing choices and intercept option (OLS has no regularization hyperparameter)\n",
        "param_grid = {\n",
        "    'var_thresh__threshold': [0.0, 1e-5, 1e-3],\n",
        "    'pca__n_components': [None, 50, 100, 200],   # None => PCA leaves all components\n",
        "    'reg__fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    cv=kf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "print(\"Running GridSearchCV (this may take some time depending on grid size)...\")\n",
        "start = time.time()\n",
        "grid.fit(X, y)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "best_rmse = -grid.best_score_\n",
        "print(f\"GridSearchCV finished in {elapsed:.1f}s\")\n",
        "print(\"Best CV RMSE (log-target):\", best_rmse)\n",
        "print(\"Best params (MLE / OLS):\", grid.best_params_)\n",
        "\n",
        "# Final predictions (GridSearchCV already refit on full training data with best params)\n",
        "best_model = grid.best_estimator_\n",
        "log_preds = best_model.predict(X_test)\n",
        "preds = np.expm1(log_preds)\n",
        "preds[preds < 0] = 0.0\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({'Id': test_ids, 'HotelValue': preds})\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"✅ Submission saved to {OUTPUT_PATH}\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "id": "5K_P9VEOYW-P",
        "outputId": "fc8bc48a-687f-43ac-aa4d-f3a9c88eda0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1200, 81), Test shape: (260, 80)\n",
            "Removed 2 outliers.\n",
            "Performing feature engineering...\n",
            "Handling missing values...\n",
            "Encoding categorical features and transforming skewness...\n",
            "Final X shape: (1198, 235), X_test shape: (260, 235)\n",
            "Setting up LinearRegression (MLE) pipeline and GridSearchCV...\n",
            "Running GridSearchCV (this may take some time depending on grid size)...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "GridSearchCV finished in 13.1s\n",
            "Best CV RMSE (log-target): 0.12645204539751617\n",
            "Best params (MLE / OLS): {'pca__n_components': 100, 'reg__fit_intercept': True, 'var_thresh__threshold': 0.0}\n",
            "✅ Submission saved to submission.csv\n",
            "     Id     HotelValue\n",
            "0   893  147340.464456\n",
            "1  1106  327968.767957\n",
            "2   414   89316.296657\n",
            "3   523  171097.429181\n",
            "4  1037  326351.172306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YashubG:"
      ],
      "metadata": {
        "id": "Gws6IQVOYV4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "cMYKqS6_kTCT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91FcOZlm0Vay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Train Random Forest Model\n",
        "# ---------------------------\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=12,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "rf.fit(X, y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Set\n",
        "# ---------------------------\n",
        "log_preds = rf.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p if target was log-transformed\n",
        "final_preds[final_preds < 0] = 0   # avoid negative values\n",
        "\n",
        "# ---------------------------\n",
        "# Save Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"RandomForest.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53oU4cvZkVQc",
        "outputId": "6499faa7-c7cc-46c3-9133-34b88353b4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random Forest model trained and submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  142248.956122\n",
            "1  1106  320257.951012\n",
            "2   414  113263.362772\n",
            "3   523  150685.392453\n",
            "4  1037  311892.583676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "ihq7S5Zhl-2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Train Gradient Boosting Model\n",
        "# ---------------------------\n",
        "gb = GradientBoostingRegressor(\n",
        "    n_estimators=500,     # number of boosting stages\n",
        "    learning_rate=0.1,   # smaller = more robust\n",
        "    max_depth=5,          # depth of each tree\n",
        "    subsample=0.8,        # for stochastic boosting\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gb.fit(X, y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Set\n",
        "# ---------------------------\n",
        "log_preds = gb.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p if y was log-transformed\n",
        "final_preds[final_preds < 0] = 0   # ensure no negatives\n",
        "\n",
        "# ---------------------------\n",
        "# Save Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"GradientBoost.csv\", index=False)\n",
        "\n",
        "print(\"✅ Gradient Boosting model trained and submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK5s0-GDmBFB",
        "outputId": "b68dc7cc-c823-463b-e332-4cfa648356cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gradient Boosting model trained and submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  141322.904380\n",
            "1  1106  322125.270717\n",
            "2   414  103823.530234\n",
            "3   523  147100.911476\n",
            "4  1037  332787.447911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "47IEtLx2CxGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Train Linear Regression\n",
        "# ---------------------------\n",
        "print(\"Training Linear Regression model...\")\n",
        "lin_reg = LinearRegression(n_jobs=-1)\n",
        "lin_reg.fit(X, y)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = lin_reg.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p transform\n",
        "final_preds[final_preds < 0] = 0   # ensure no negative values\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"linear_regression.csv\", index=False)\n",
        "\n",
        "print(\"✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV8375AqHrDG",
        "outputId": "42a94ca1-fbe0-4c5e-b6da-3abf34a965e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Linear Regression model...\n",
            "Training complete.\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.657115\n",
            "1  1106  328934.353821\n",
            "2   414  105309.178068\n",
            "3   523  165803.564443\n",
            "4  1037  311199.481472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-fold Cross validation"
      ],
      "metadata": {
        "id": "Cbm7mnmxI5-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# K-Fold Cross Validation Setup\n",
        "# ---------------------------\n",
        "N_FOLDS = 5\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# ---------------------------\n",
        "# Initialize Model\n",
        "# ---------------------------\n",
        "lin_reg = LinearRegression(n_jobs=-1)\n",
        "\n",
        "# ---------------------------\n",
        "# Cross-validation\n",
        "# ---------------------------\n",
        "rmsle_scores = []\n",
        "\n",
        "print(f\"Running {N_FOLDS}-Fold Cross Validation for Linear Regression...\\n\")\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y), 1):\n",
        "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    lin_reg.fit(X_train, y_train)\n",
        "    y_pred = lin_reg.predict(X_valid)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
        "    rmsle_scores.append(rmsle)\n",
        "\n",
        "    print(f\"Fold {fold}: RMSLE = {rmsle:.5f}\")\n",
        "\n",
        "print(\"\\n✅ Cross-validation complete.\")\n",
        "print(f\"Average RMSLE across {N_FOLDS} folds: {np.mean(rmsle_scores):.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train Final Model on Full Data\n",
        "# ---------------------------\n",
        "lin_reg.fit(X, y)\n",
        "print(\"\\nTraining final model on full dataset... Done.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = lin_reg.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"kFold.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrHN4In8JDh8",
        "outputId": "b87083c6-bd2b-4456-ab55-2c2d52a180c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 5-Fold Cross Validation for Linear Regression...\n",
            "\n",
            "Fold 1: RMSLE = 0.12644\n",
            "Fold 2: RMSLE = 0.12862\n",
            "Fold 3: RMSLE = 0.14658\n",
            "Fold 4: RMSLE = 0.12526\n",
            "Fold 5: RMSLE = 0.12147\n",
            "\n",
            "✅ Cross-validation complete.\n",
            "Average RMSLE across 5 folds: 0.12967\n",
            "\n",
            "Training final model on full dataset... Done.\n",
            "\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.657115\n",
            "1  1106  328934.353821\n",
            "2   414  105309.178068\n",
            "3   523  165803.564443\n",
            "4  1037  311199.481472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOCV"
      ],
      "metadata": {
        "id": "GsT9aA3qJp4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Leave-One-Out CV Setup\n",
        "# ---------------------------\n",
        "loo = LeaveOneOut()\n",
        "n_splits = loo.get_n_splits(X)\n",
        "\n",
        "lin_reg = LinearRegression(n_jobs=-1)\n",
        "rmsle_scores = []\n",
        "\n",
        "print(f\"Running Leave-One-Out Cross Validation on {n_splits} samples...\\n\")\n",
        "\n",
        "# ---------------------------\n",
        "# LOOCV Loop\n",
        "# ---------------------------\n",
        "for i, (train_idx, valid_idx) in enumerate(loo.split(X), 1):\n",
        "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    lin_reg.fit(X_train, y_train)\n",
        "    y_pred = lin_reg.predict(X_valid)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
        "    rmsle_scores.append(rmsle)\n",
        "\n",
        "    if i % 100 == 0 or i == n_splits:  # print progress every 100 samples\n",
        "        print(f\"Processed {i}/{n_splits} samples, Current RMSLE: {rmsle:.5f}\")\n",
        "\n",
        "print(\"\\n✅ LOOCV complete.\")\n",
        "print(f\"Average RMSLE across all samples: {np.mean(rmsle_scores):.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train Final Model on Full Data\n",
        "# ---------------------------\n",
        "lin_reg.fit(X, y)\n",
        "print(\"\\nTraining final Linear Regression model on full dataset... Done.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = lin_reg.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"loocv.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE5oOpfUJrun",
        "outputId": "31220dbd-2517-4ae9-d41e-f95ac6cab85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Leave-One-Out Cross Validation on 1198 samples...\n",
            "\n",
            "Processed 100/1198 samples, Current RMSLE: 0.00944\n",
            "Processed 200/1198 samples, Current RMSLE: 0.05119\n",
            "Processed 300/1198 samples, Current RMSLE: 0.01004\n",
            "Processed 400/1198 samples, Current RMSLE: 0.06401\n",
            "Processed 500/1198 samples, Current RMSLE: 0.17141\n",
            "Processed 600/1198 samples, Current RMSLE: 0.05238\n",
            "Processed 700/1198 samples, Current RMSLE: 0.02046\n",
            "Processed 800/1198 samples, Current RMSLE: 0.07474\n",
            "Processed 900/1198 samples, Current RMSLE: 0.03780\n",
            "Processed 1000/1198 samples, Current RMSLE: 0.01810\n",
            "Processed 1100/1198 samples, Current RMSLE: 0.17214\n",
            "Processed 1198/1198 samples, Current RMSLE: 0.13056\n",
            "\n",
            "✅ LOOCV complete.\n",
            "Average RMSLE across all samples: 0.08278\n",
            "\n",
            "Training final Linear Regression model on full dataset... Done.\n",
            "\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.657115\n",
            "1  1106  328934.353821\n",
            "2   414  105309.178068\n",
            "3   523  165803.564443\n",
            "4  1037  311199.481472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression"
      ],
      "metadata": {
        "id": "vsofCZ0GKkNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Leave-One-Out CV Setup\n",
        "# ---------------------------\n",
        "loo = LeaveOneOut()\n",
        "n_splits = loo.get_n_splits(X)\n",
        "\n",
        "ridge = Ridge(alpha=1.0, random_state=42)  # You can tune alpha later\n",
        "rmsle_scores = []\n",
        "\n",
        "print(f\"Running Leave-One-Out Cross Validation for Ridge Regression on {n_splits} samples...\\n\")\n",
        "\n",
        "# ---------------------------\n",
        "# LOOCV Loop\n",
        "# ---------------------------\n",
        "for i, (train_idx, valid_idx) in enumerate(loo.split(X), 1):\n",
        "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
        "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "\n",
        "    ridge.fit(X_train, y_train)\n",
        "    y_pred = ridge.predict(X_valid)\n",
        "\n",
        "    rmsle = np.sqrt(mean_squared_log_error(np.expm1(y_valid), np.expm1(y_pred)))\n",
        "    rmsle_scores.append(rmsle)\n",
        "\n",
        "    if i % 100 == 0 or i == n_splits:  # Print progress every 100 samples\n",
        "        print(f\"Processed {i}/{n_splits} samples, Current RMSLE: {rmsle:.5f}\")\n",
        "\n",
        "print(\"\\n✅ LOOCV complete.\")\n",
        "print(f\"Average RMSLE across all samples: {np.mean(rmsle_scores):.5f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train Final Model on Full Data\n",
        "# ---------------------------\n",
        "ridge.fit(X, y)\n",
        "print(\"\\nTraining final Ridge Regression model on full dataset... Done.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = ridge.predict(X_test_final)\n",
        "final_preds = np.expm1(log_preds)  # Reverse log1p transform\n",
        "final_preds[final_preds < 0] = 0   # Ensure no negatives\n",
        "\n",
        "# ---------------------------\n",
        "# Create Submission File\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"ridgeRegression.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keUrKJHVKl8v",
        "outputId": "a25117b8-f254-4074-db1b-7e941b093929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Leave-One-Out Cross Validation for Ridge Regression on 1198 samples...\n",
            "\n",
            "Processed 100/1198 samples, Current RMSLE: 0.00124\n",
            "Processed 200/1198 samples, Current RMSLE: 0.06196\n",
            "Processed 300/1198 samples, Current RMSLE: 0.00458\n",
            "Processed 400/1198 samples, Current RMSLE: 0.07191\n",
            "Processed 500/1198 samples, Current RMSLE: 0.13652\n",
            "Processed 600/1198 samples, Current RMSLE: 0.04300\n",
            "Processed 700/1198 samples, Current RMSLE: 0.02222\n",
            "Processed 800/1198 samples, Current RMSLE: 0.13733\n",
            "Processed 900/1198 samples, Current RMSLE: 0.04268\n",
            "Processed 1000/1198 samples, Current RMSLE: 0.00954\n",
            "Processed 1100/1198 samples, Current RMSLE: 0.19361\n",
            "Processed 1198/1198 samples, Current RMSLE: 0.11449\n",
            "\n",
            "✅ LOOCV complete.\n",
            "Average RMSLE across all samples: 0.07832\n",
            "\n",
            "Training final Ridge Regression model on full dataset... Done.\n",
            "\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147219.487747\n",
            "1  1106  331851.841627\n",
            "2   414  104549.424486\n",
            "3   523  166146.445081\n",
            "4  1037  311794.030132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lasso Regression"
      ],
      "metadata": {
        "id": "_MT5lIWCLgop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# Lasso model\n",
        "lasso = Lasso(alpha=0.001, max_iter=50000, random_state=42)\n",
        "\n",
        "lasso.fit(X_scaled, y)\n",
        "print(\"✅ Model trained successfully (no convergence warnings).\")\n",
        "\n",
        "# Predictions\n",
        "log_preds = lasso.predict(X_test_scaled)\n",
        "final_preds = np.expm1(log_preds)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ submission.csv created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsItkh3xLvLX",
        "outputId": "c0a630e4-9e96-4bb2-e1b9-925b16ad255b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained successfully (no convergence warnings).\n",
            "✅ submission.csv created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic nets"
      ],
      "metadata": {
        "id": "R4lpwqy2L7zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ================================\n",
        "# Scale features (important!)\n",
        "# ================================\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# ================================\n",
        "# Elastic Net with Cross-Validation\n",
        "# ================================\n",
        "elastic_cv = ElasticNetCV(\n",
        "    l1_ratio=[.1, .3, .5, .7, .9, .95, 1],\n",
        "    alphas=np.logspace(-4, 1, 50),\n",
        "    cv=5,\n",
        "    max_iter=100000,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training Elastic Net with CV...\")\n",
        "elastic_cv.fit(X_scaled, y)\n",
        "print(\"Training complete.\")\n",
        "print(f\"Best alpha: {elastic_cv.alpha_:.6f}\")\n",
        "print(f\"Best l1_ratio: {elastic_cv.l1_ratio_:.2f}\")\n",
        "\n",
        "# ================================\n",
        "# Predict on Test Data\n",
        "# ================================\n",
        "log_preds = elastic_cv.predict(X_test_scaled)\n",
        "final_preds = np.expm1(log_preds)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ================================\n",
        "# Create Submission File\n",
        "# ================================\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGf3CIioL9v_",
        "outputId": "1ab090c1-d5a5-4fe6-da37-e6a9b0eb1efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Elastic Net with CV...\n",
            "Training complete.\n",
            "Best alpha: 0.028118\n",
            "Best l1_ratio: 0.10\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147540.826955\n",
            "1  1106  317283.985683\n",
            "2   414  105870.135758\n",
            "3   523  159955.124294\n",
            "4  1037  304075.633259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian Approach + Conjugate Priors"
      ],
      "metadata": {
        "id": "hoY8E9I8bFGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Add intercept term\n",
        "# ---------------------------\n",
        "X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "X_test_aug = np.hstack([np.ones((X_test_final.shape[0], 1)), X_test_final])\n",
        "n, p = X_aug.shape\n",
        "\n",
        "# ---------------------------\n",
        "# Prior hyperparameters\n",
        "# ---------------------------\n",
        "mu_0 = np.zeros(p)             # prior mean of coefficients\n",
        "Lambda_0 = np.eye(p) * 1e-6    # prior precision (tiny, almost uninformative)\n",
        "a_0 = 1e-6                     # prior shape for sigma^2\n",
        "b_0 = 1e-6                     # prior scale for sigma^2\n",
        "\n",
        "# ---------------------------\n",
        "# Posterior for coefficients (beta | sigma^2, y)\n",
        "# ---------------------------\n",
        "# Posterior precision and mean\n",
        "Lambda_n = Lambda_0 + X_aug.T @ X_aug\n",
        "mu_n = np.linalg.solve(Lambda_n, Lambda_0 @ mu_0 + X_aug.T @ y)\n",
        "\n",
        "# Posterior parameters for sigma^2\n",
        "a_n = a_0 + n / 2\n",
        "residuals = y - X_aug @ mu_n\n",
        "b_n = b_0 + 0.5 * (residuals.T @ residuals + (mu_n - mu_0).T @ Lambda_0 @ (mu_n - mu_0))\n",
        "\n",
        "# Posterior mean of sigma^2\n",
        "sigma2_post = b_n / (a_n - 1)\n",
        "\n",
        "# Posterior predictive mean for test set\n",
        "y_pred_test = X_test_aug @ mu_n\n",
        "\n",
        "# ---------------------------\n",
        "# Reverse log-transform\n",
        "# ---------------------------\n",
        "final_preds = np.expm1(y_pred_test)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create submission file\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ Bayesian regression submission created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-cBXYcGimrG",
        "outputId": "810f171d-6037-4aba-9c98-c72935750223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bayesian regression submission created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  147395.155681\n",
            "1  1106  328934.870491\n",
            "2   414  105309.390046\n",
            "3   523  165803.205292\n",
            "4  1037  311199.689455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian + MAP estimate"
      ],
      "metadata": {
        "id": "cQDmUKpHoEET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Add intercept term\n",
        "# ---------------------------\n",
        "X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "X_test_aug = np.hstack([np.ones((X_test_final.shape[0], 1)), X_test_final])\n",
        "n, p = X_aug.shape\n",
        "\n",
        "# ---------------------------\n",
        "# MAP / Ridge parameters\n",
        "# ---------------------------\n",
        "tau2 = 1.0       # prior variance for coefficients\n",
        "sigma2 = 1.0     # assumed noise variance\n",
        "lambda_ = sigma2 / tau2  # regularization strength\n",
        "\n",
        "# ---------------------------\n",
        "# Compute MAP estimate\n",
        "# ---------------------------\n",
        "beta_map = np.linalg.solve(X_aug.T @ X_aug + lambda_ * np.eye(p), X_aug.T @ y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on test data\n",
        "# ---------------------------\n",
        "y_pred_test = X_test_aug @ beta_map\n",
        "\n",
        "# Reverse log-transform\n",
        "final_preds = np.expm1(y_pred_test)\n",
        "final_preds[final_preds < 0] = 0\n",
        "\n",
        "# ---------------------------\n",
        "# Create submission file\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ Bayesian MAP regression submission created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WoTsqHwoHqT",
        "outputId": "2a0cacf2-83c7-45ef-80cc-d30d411d1d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bayesian MAP regression submission created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  146199.896460\n",
            "1  1106  333192.071502\n",
            "2   414  105398.256957\n",
            "3   523  165257.086300\n",
            "4  1037  312337.850589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K nearest neighbours"
      ],
      "metadata": {
        "id": "N0w4v70fvpd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------------------------\n",
        "# Scale features (important for KNN)\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# ---------------------------\n",
        "# KNN Model with Grid Search\n",
        "# ---------------------------\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # 1 = Manhattan, 2 = Euclidean\n",
        "}\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "grid = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_log_error', n_jobs=-1)\n",
        "print(\"🔧 Performing Grid Search for KNN...\")\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"✅ Grid Search complete!\")\n",
        "print(f\"Best parameters: {grid.best_params_}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Train final KNN with best params\n",
        "# ---------------------------\n",
        "knn_best = grid.best_estimator_\n",
        "knn_best.fit(X_scaled, y)\n",
        "\n",
        "# ---------------------------\n",
        "# Predict on Test Data\n",
        "# ---------------------------\n",
        "log_preds = knn_best.predict(X_test_scaled)\n",
        "final_preds = np.expm1(log_preds)  # reverse log1p\n",
        "final_preds[final_preds < 0] = 0   # ensure no negative values\n",
        "\n",
        "# ---------------------------\n",
        "# Create submission file\n",
        "# ---------------------------\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_ids,\n",
        "    \"HotelValue\": final_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"✅ submission.csv created successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGGDwnrbvrIv",
        "outputId": "3c5cf313-9b68-4c4c-e565-4b045a2f2477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Performing Grid Search for KNN...\n",
            "✅ Grid Search complete!\n",
            "Best parameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
            "✅ submission.csv created successfully!\n",
            "     Id     HotelValue\n",
            "0   893  129493.630228\n",
            "1  1106  272446.984455\n",
            "2   414  101369.955521\n",
            "3   523  139889.126281\n",
            "4  1037  334962.130438\n"
          ]
        }
      ]
    }
  ]
}